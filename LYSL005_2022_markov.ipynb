{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMoFh1fRgRMSLp3uG8QYcD9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mwauquier/LYSL005_machine_creativity/blob/main/LYSL005_2022_markov.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Générer du texte avec des chaînes de Markov"
      ],
      "metadata": {
        "id": "ZVy1gV7OFhne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*NB : un notebook Google Colab crée une instance de machine virtuelle à chaque utilisation. Vous devez donc relancer les installations et chargements nécessaires au lancement du code à chaque ouverture du notebook.*"
      ],
      "metadata": {
        "id": "-RZ4y_ie-BRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous utiliserons pour cela le module `markovify` qui permet d'entraîner un modèle de chaînes de Markov sous Python.\n",
        "\n",
        "Vous retrouverez la documentation au lien suivant : https://github.com/jsvine/markovify\n",
        "\n",
        "Notez que l'auteur donne le détail annoté du code derrière le module au lien https://github.com/jsvine/markovify/blob/master/markovify/chain.py\n"
      ],
      "metadata": {
        "id": "uHxZSmhFvgzj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans son utilisation la plus basique, le module permet la génération de texte en trois étapes :\n",
        "- le chargement d'un corpus d'entraînement\n",
        "- l'entraînement du modèle\n",
        "- la production de texte nouveau"
      ],
      "metadata": {
        "id": "G2ns3KnI7Hig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour commencer, on installe et on charge le module `markovify`"
      ],
      "metadata": {
        "id": "FX55to8x60L5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install markovify \n",
        "\n",
        "import markovify\n",
        "\n",
        "# Notez que dans le notebook Colab, la commande \"pip\" est précédée d'un point d'exclamation\n",
        "# Ce n'est pas le cas si vous travaillez directement depuis un terminal"
      ],
      "metadata": {
        "id": "zgl8vAOA6i_l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "667cb321-2605-47f8-b5b3-6307d4fa4e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting markovify\n",
            "  Downloading markovify-0.9.4.tar.gz (27 kB)\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 13.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: markovify\n",
            "  Building wheel for markovify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for markovify: filename=markovify-0.9.4-py3-none-any.whl size=18629 sha256=adcc9c060499bae30e7722b8949941c1cc3249fd31d65e9c104fe7cd0eb69ebd\n",
            "  Stored in directory: /root/.cache/pip/wheels/36/c5/82/11125c5a7dadec27ef49ac2b3a12d3b1f79ff7333c92a9b67b\n",
            "Successfully built markovify\n",
            "Installing collected packages: unidecode, markovify\n",
            "Successfully installed markovify-0.9.4 unidecode-1.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On charge ensuite le corpus à partir duquel on va entraîner notre modèle (à partir duquel notre chaîne de Markov va définir ses règles probabilistes)"
      ],
      "metadata": {
        "id": "uPqNPr5D7A8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code valable si vous travaillez localement sur votre machine\n",
        "\n",
        "with open(\"/path/to/your/corpus.txt\") as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "JuxWGNAW7jf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si vous souhaitez travailler directement depuis le notebook, il vous faudra téléverser le corpus sur votre Drive. Vous pourrez alors accéder à votre corpus à l'aide du code suivant. \n",
        "\n",
        "Attention, une autorisation d'accès à votre compte Google sera nécessaire !"
      ],
      "metadata": {
        "id": "g3UnAkCr7qeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code valable si vous travaillez en ligne sur le notebook Colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1yi0VA6y7pun",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbee8fcd-e034-40ae-caae-5c6a1bf3fb9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/path/to/your/corpus.txt') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "QXbNjRSs8Kph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On construit le modèle"
      ],
      "metadata": {
        "id": "Oy7cKg_G9OUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_model = markovify.Text(text)"
      ],
      "metadata": {
        "id": "N4VST04f9PpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On génère du texte"
      ],
      "metadata": {
        "id": "QKUH6wpQ9RDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_model.make_sentence()) \n",
        "\n",
        "# En l'occurrence, ici, on l'imprime directement mais on pourra l'enregistrer dans une variable"
      ],
      "metadata": {
        "id": "4ka6Cntq9aq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quelques informations et éléments complémentaires"
      ],
      "metadata": {
        "id": "XWSa6hvZ-aTm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Ci-dessous quelques pistes de réflexion / d'exploration pour générer du texte avec `markovify`*\n",
        "\n"
      ],
      "metadata": {
        "id": "X09-EOb5DwAD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Argument"
      ],
      "metadata": {
        "id": "crfasxc2-51n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La fonction markovify.Text peut prendre l'argument 'state_size' : à quoi cela correspond-t-il ?"
      ],
      "metadata": {
        "id": "xssXk3CjD-4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_model = markovify.Text(text, state_size=3)"
      ],
      "metadata": {
        "id": "_Mj64uZbCHTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Longueur de l'output"
      ],
      "metadata": {
        "id": "jNK-S7bH_CG8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vous pouvez limiter la taille des phrases à générer avec la fonction 'make_short_sentence()' (qui prend l'argument 'max_char')\n"
      ],
      "metadata": {
        "id": "ULzSfkD2ECAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_model.make_short_sentence(max_chars=100))"
      ],
      "metadata": {
        "id": "xsZQxF76CqEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combinaison de modèles"
      ],
      "metadata": {
        "id": "EdMYzqkA_GL6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vous pouvez créer un modèle qui combine plusieurs modèles entraînés indépendamment"
      ],
      "metadata": {
        "id": "unK8hUYIEE5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_model = markovify.combine([model_1, model_2], [1,1]) # Les nombres entre crochets correspondent au poids que vous donnez respectivement à chaque modèle\n",
        "\n",
        "# Il s'utilise alors comme n'importe quel autre modèle\n",
        "print(combined_model.make_sentence())"
      ],
      "metadata": {
        "id": "u3W9TH6eBI40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Format du corpus d'entrée"
      ],
      "metadata": {
        "id": "Yo_1FHSG_JPj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Par défaut, l'algorithme exclut de l'entraînement les phrases qui contiennent des caractères jugés problématiques (parenthèses, crochets, guillements...). Plusieurs solutions sont possibles pour conserver ces phrases : les arguments 'well_formed' et 'reject_reg'."
      ],
      "metadata": {
        "id": "l64jvWpCDqSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# L'argument \"well_formed\" est par défaut fixé à True. Le passer à False permet d'inclure par défaut les phrases 'fautives'\n",
        "text_model = markovify.Text(text, well_formed=False)\n",
        "\n",
        "# L'argument \"reject_reg\" permet de spécifier dans le cadre d'une expression régulière les éléments à ne pas exclure. L'utilisation de cet argument nécessite que 'well_formed' soit fixé à True\n",
        "\n",
        "text_model = markovify.Text(text, reject_reg=r'#') # En l'occurrence, ici, on autorise les phrases contenant un #"
      ],
      "metadata": {
        "id": "XROUE3phFyN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vous pouvez aussi pré-traiter votre corpus en amont de l'entraînement du modèle (que ce soit avec des fonctions simples à base d'expressions régulières, ou du traitement plus poussé de post-tagging, lemmatisation, etc)."
      ],
      "metadata": {
        "id": "cW4aGNE4NGNf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Originalité du texte généré"
      ],
      "metadata": {
        "id": "iNHMyv9A_L1k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Par défaut, la fonction 'markovify.Text()' essaye de limiter le recouvrement entre les phrases produites et les phrases vues en entraînement. Quel est le seuil fixé par défaut ? Trouvez la réponse dans la documentation.\n",
        "\n",
        "Ces seuils peuvent être modifiés dans la fonction 'make_sentence'."
      ],
      "metadata": {
        "id": "sMEXVq8qIQf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_model.make_sentence(max_overlap_ratio = X)) # où X est compris entre 0 et 1\n",
        "\n",
        "print(text_model.make_sentence(max_overlap_total = X)) # où X est un nombre entier\n",
        "\n",
        "print(text_model.make_sentence(test_output = False)) # pour supprimer dans son entiereté l'étape de vérification"
      ],
      "metadata": {
        "id": "kTqOMf-sJf0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si l'on ne veut pas modifier ce seuil, on peut jouer sur la fonction 'make_sentence' et sur le nombre d'itérations qu'elle produit afin d'éviter un recouvrement trop important, et ce à l'aide de l'argument \"tries\". La valeur par défaut est 10."
      ],
      "metadata": {
        "id": "1xIGIntsIQlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_model.make_sentence(tries=100))"
      ],
      "metadata": {
        "id": "EjQousYxMnrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Traitement des gros corpus"
      ],
      "metadata": {
        "id": "SeWiFVYd_Pht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Par défaut, le module charge et garde en mémoire votre corpus, notamment afin de comparer les phrases vues et celles générées. Cela peut être problématique si vous travaillez avec un corpus de grande taille.\n",
        "\n",
        "Pour résoudre cela, vous pouvez signifier au module de ne pas garder en mémoire le corpus. il suffit alors de préciser l'argument 'retain_original' et de le fixer à False lors de l'entraînement"
      ],
      "metadata": {
        "id": "xN39vK2XxNnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"path/to/my/huge/corpus.txt\") as f:\n",
        "    text_model = markovify.Text(f, retain_original=False)\n",
        "\n",
        "print(text_model.make_sentence())"
      ],
      "metadata": {
        "id": "6rlR-YqpQbAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Une seconde façon de faire consiste à lire le corpus ligne par ligne, à entraîner pour chaque ligne un modèle, et à combiner ces modèles pour n'en faire qu'un seul. Regardez la documentation pour une idée de l'implémentation."
      ],
      "metadata": {
        "id": "oUgvfs-rQgCS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Génération du modèle"
      ],
      "metadata": {
        "id": "mGzKSj9c_UM0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le code comprend la fonction `markovify.NewlineText()` qui s'utilise en lieu et place de la fonction `markovify.Text` : quelle est la différence ?"
      ],
      "metadata": {
        "id": "10-cxh9_-nin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "newline_model = markovify.NewlineText"
      ],
      "metadata": {
        "id": "8IB5McUF-mUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Divers"
      ],
      "metadata": {
        "id": "Y7SFHBjM_al0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notez que vous pouvez exporter le modèle complet, ou simplement la chaîne de Markov sous-jacente, afin de pouvoir les réutiliser ultérieurement. Reportez-vous à la documentation pour plus de détails."
      ],
      "metadata": {
        "id": "MwiIigUBQwQv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si vous souhaitez travailler avec des corpus (en anglais) directement interrogeables en ligne, vous pouvez utiliser le module 'nltk', et plus précisément le package 'gutenberg' (qui donne accès à des oeuvres comme des pièces de Shakespeare, des romans de Austen, Carroll, etc). De nombreuses ressources sont disponibles en ligne à ce sujet."
      ],
      "metadata": {
        "id": "vKYCe_b6RTDa"
      }
    }
  ]
}