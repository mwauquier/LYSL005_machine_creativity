{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzSZqVJjlpCXnxEY3SsVOV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mwauquier/LYSL005_machine_creativity/blob/main/LYSL005_2022_rnn_adapted.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Générer du texte avec des RNN"
      ],
      "metadata": {
        "id": "EZSjoT6zbsFJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous utiliserons pour cela un module adapté par Donald Dong qui permet d'entraîner rapidement un RNN pour la génération de texte, appelé `rnn-text-gen`. La documentation autour du module en question est [disponible sur Github](https://github.com/donaldong/rnn-text-gen)."
      ],
      "metadata": {
        "id": "HEIZgF4tzLON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Contrairement au module `markovify`, nous n'allons pas installer le module et l'importer comme n'importe quel module Python. Nous allons ici devoir récupérer le répertoire git et l'importer ici.\n",
        "\n",
        "On commence pour cela par cloner le répertoire Git."
      ],
      "metadata": {
        "id": "FmPRRWmtcqvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/donaldong/rnn-text-gen.git"
      ],
      "metadata": {
        "id": "XE8ASkti0HhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pensez à remplacer le fichier 'text_generator.py' présent dans le répertoire 'rnn-text-gen/src' par le fichier disponible sur iCampus afin de pouvoir faire tourner le reste du code sous Tensorflow 2. Voir les détails de la manipulation sur iCampus."
      ],
      "metadata": {
        "id": "RTtTSSKZ_U26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il nous faut alors dire au système (ici, notre système virtuel) où se trouve le module que l'on a récupé. On le fait à l'aide du code dans la cellule suivante."
      ],
      "metadata": {
        "id": "8mMnEH10dCXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/content/rnn-text-gen')"
      ],
      "metadata": {
        "id": "lOzf7goh0VWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Il nous faut maintenant importer les classes et libraires pertinentes"
      ],
      "metadata": {
        "id": "d8QTsvQkdm-E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqFkQ0wYzFrS"
      },
      "outputs": [],
      "source": [
        "# On importe les classes issues du module custom que nous avons cloné\n",
        "from src.text_generator import RNNTextGenerator\n",
        "from src.dataset import Dataset\n",
        "\n",
        "# On importe les librairies classiques nécessaires pour la suite\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On peut alors commencer à entraîner notre RNN.\n",
        "\n",
        "On commence par charger notre corpus d'entraînement. Ici, le module vient avec quelques corpus, dont on peut regarder rapidement à quoi ils ressemblent."
      ],
      "metadata": {
        "id": "0g0DY-49eFUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('/content/rnn-text-gen/data/alice.txt')\n",
        "text = f.read()\n",
        "print(text[:400])"
      ],
      "metadata": {
        "id": "2ZGTyqwjeRwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il nous faut maintenant définir les paramètres d'entraînement. Parmi ces paramètres, on trouve :\n",
        "- La taille des batchs (batch_size)\n",
        "- La longueur des séquences (seq_length)\n",
        "- Le nombre d'époch (epoch)\n",
        "- Le taux d'apprentissage (learning_rate)"
      ],
      "metadata": {
        "id": "gl5gvPrikF1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 25\n",
        "learning_rate = 0.01\n",
        "epoch = 1\n",
        "batch_size = 25"
      ],
      "metadata": {
        "id": "pX_RwrTDePBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On peut alors traiter le corpus, c'est-à-dire créer les vecteurs qui serviront d'input au RNN. Le présent module propose par la fonction Dataset de transformer le corpus en un ensemble de batchs comprenant *n* séquences de longueur *j* de vecteurs one-hot (où *n* correspond à la valeur définie par batch_size, et *j* à la longueur des séquences définie par seq_length)\n",
        "\n",
        "Notons qu'ici, la fonction crée des vecteurs pour les caractères, mais on peut de façon générale choisir de faire des vecteurs pour les mots eux-mêmes et non les caractères.\n",
        "\n",
        "De même, les RNNs peuvent prendre en entrée des vecteurs de type *word embeddings*, mais nous nous limiterons ici aux vecteurs one-hot.\n"
      ],
      "metadata": {
        "id": "OAWwKYzQkOzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alice_dataset = Dataset(['/content/rnn-text-gen/data/alice.txt'], seq_length)"
      ],
      "metadata": {
        "id": "ZO-ZBDJskN6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On peut alors entraîner le modèle à l'aide de la fonction `RNNTextGenerator()`. Un argument important de cette fonction est le type d'unités que l'on utilise (ici BasicRNNCell). On pourra plus tard utiliser des unités de type LSTM ou GRU pour entraîner les réseaux de neurones correspondants."
      ],
      "metadata": {
        "id": "koy7KvOrlEo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model = RNNTextGenerator(\n",
        "    seq_length,\n",
        "    alice_dataset.vocab_size,\n",
        "    rnn_cell=tf.compat.v1.nn.rnn_cell.BasicRNNCell,\n",
        "    learning_rate=learning_rate,\n",
        "    epoch=epoch,\n",
        "    batch_size=batch_size,\n",
        ")"
      ],
      "metadata": {
        "id": "cckpjz4dzarw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Une façon d'évaluer nos paramètres et le degré de convergence de notre RNN consiste à voir comment évoluent la précision (Accuracy) et la fonction objectif (loss function).\n",
        "\n",
        "On commence par faire converger le modèle sur nos données, et on sauvegarde les scores dans une variable."
      ],
      "metadata": {
        "id": "guAfGKL9t8PY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model_scores = rnn_model.fit(\n",
        "    alice_dataset,\n",
        "    save_scores=True\n",
        ")"
      ],
      "metadata": {
        "id": "hUtLVZ1Jt8t_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On peut alors produire une visualisation graphique de l'évolution de ces scores."
      ],
      "metadata": {
        "id": "MgKj-GaHvENk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(figsize=(15, 6), ncols=2)\n",
        "rnn_model_scores['accuracy'].plot(\n",
        "    ax=axes[0], title='Accuracy (Train)'\n",
        ")\n",
        "rnn_model_scores['loss'].plot(\n",
        "    ax=axes[1], title='Loss (Train)'\n",
        ")\n",
        "for ax in axes:\n",
        "    ax.set(xlabel='Steps')"
      ],
      "metadata": {
        "id": "BSqOKcdKvHEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La courbe de la fonction objectif doit normalement une courbe descendante d'abord rapide puis qui ralentit. Si la courbe ne se stabilise cependant pas (qu'il y a beaucoup de pics par exemple), on considère que le RNN n'a pas convergé. Un modèle ne converge pas quand la fonction objectif ne se stabilise pas. Une raison à cette non-convergence peut s'expliquer par le nombre limité d'epochs (1) que nous avons fixé. On peut donc choisir de réentraîner notre RNN avec un nombre d'epochs plus élevé, par exemple.\n",
        "\n",
        "Sachez que l'on peut aussi affiner notre modèle sans le réentraîner de 0 en le va le 'fit' sur nos données (on peut considérer cela comme un epoch). On peut ainsi demander au modèle de s'affiner un certain nombre de fois, ou durant une certaine période, comme on le fait ci-dessous.\n",
        "\n",
        "De façon assez intéressante, on peut suivre l'évolution en direct de ces scores et de l'état de la prédiction en temps réel à mesure que le RNN s'entraîne."
      ],
      "metadata": {
        "id": "aXOg9EozveVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# On importe la fonction native du module permettant de fixer une durée maximale à l'entraînement\n",
        "from src.time_limit import time_limit\n",
        "\n",
        "# On définit la durée de l'entraînement\n",
        "for _ in time_limit(seconds=30): \n",
        "  # On affine le modèle\n",
        "  rnn_model.fit(alice_dataset)\n",
        "  acc, loss = rnn_model.score(alice_dataset)\n",
        "  # On imprime à chaque epoch la précision et la valeur de la loss function\n",
        "  print('test acc: {}, test loss: {}'.format(\n",
        "        acc, loss\n",
        "    ))\n",
        "  # On demande à chaque epoch d'imprimer une séquence de 100 caractères prédits à partir de la séquence initiale 'Yes, but '\n",
        "  start_seq = 'Yes, but '\n",
        "  print(start_seq + rnn_model.generate(\n",
        "        alice_dataset,\n",
        "        start_seq,\n",
        "        100\n",
        "    ))\n",
        "  print('-----------------------')"
      ],
      "metadata": {
        "id": "aZXGLh_k36uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quelque soit la performance de votre RNN, il est en tout cas déjà prêt pour la génération de phrase. Générer une séquence se fait à l'aide de la fonction `generate()`. La fonction prend en argument le dataset (c'est-à-dire le dictionnaire contenant les équivalences entre les vecteurs one-hot et les symboles correspondants), la séquence à partir de laquelle prédire, et le nombre de caractères à prédire."
      ],
      "metadata": {
        "id": "sgzov5cIyd4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pour des raisons de lisibilité, on définit la séquence d'amorce dans une variable à part\n",
        "start_seq = 'Of course '\n",
        "\n",
        "# On imprime ici directement l'amorce et le texte généré (mais on pourrait enregistrer le texte généré dans une variable par exemple)\n",
        "print(start_seq + rnn_model.generate(\n",
        "        alice_dataset,\n",
        "        start_seq,\n",
        "        500\n",
        "    ))"
      ],
      "metadata": {
        "id": "svVaARimBQH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comme dit plus haut, vous pouvez entraîner des RNN plus spécifiques, à savoir des LSTM et des réseaux de type GRU. Il suffit pour cela notamment de remplacer dans la fonction d'entraînement le `BasicRNNCell` par `LSTMCell` ou `GRUCell` (et modifier les valeurs des autres arguments si besoin)."
      ],
      "metadata": {
        "id": "Qygj-jafzUax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercice\n",
        "\n",
        "- Quels sont les paramètres qui vous permettent d'améliorer les résultats pour un petit corpus ?\n",
        "- Quel est l'impact de la taille du corpus ?\n",
        "- Quelle est la performance du RNN sur la prédiction du wikiCréole ?\n",
        "- Quel est le type de réseau de neurones qui marche le mieux (sur vos données) ?"
      ],
      "metadata": {
        "id": "j22GJOfj1ltf"
      }
    }
  ]
}